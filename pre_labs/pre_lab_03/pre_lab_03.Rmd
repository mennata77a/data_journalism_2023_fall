---
title: "pre_lab_03.Rmd"
author: "Derek Willis"
date: "2023-08-08"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(scipen=999)
```

## About this notebook

This notebook contains code and explanatory text that your should review and run as you read through two chapters on data cleaning from the course textbook, "Data Journalism with R and the Tidyverse". Answer questions and edit the document as directed.

Running this notebook will help you understand key data analysis methods and concepts that you will put into practice during this week's lab.

When you are finished running the code in this notebook, you will push changes to your course GitHub repo, and upload the link to ELMS as instructed.

## Data Cleaning, Part I

### Task 1: Load libraries and settings

**Task** Run the following code in the gray-colored codeblock below to load the tidyverse library and turn off scientific notation.

```{r}
# Remove scientific notation
options(scipen=999)
# Load the tidyverse   
library(tidyverse)
```

### Task 2: Load data

**Task** Load some [Maryland state government payments data](https://opendata.maryland.gov/Budget/State-of-Maryland-Payments-Data-FY2008-to-FY2024/7syw-q4cy) by running the following code. We'll use the guess_max() function as an argument to use the first 10 rows to set the data type. What does the first line of the red Warning message that prints out when you load the data say? What happens when you follow its instructions? Answer below. 

**Answer** The first line of the warning message reads as follows: "One or more parsing issues, call `problems()` on your data frame for details". After running 'problems()', R identified and explained  each problem it encountered while trying to show me the dataset. The main source of this problem, therefore, is that guess based on the first 10 rows.

```{r}
payments <- read_csv("data/State_of_Maryland_Payments_Data__FY2008_to_FY2024.csv", guess_max=10)
```

### Task 3: Reload data

**Task** Run the following codeblock to reload the data, using every row to set the data types. Does it show any parsing errors when you run? Answer below 

**Answer** No it does not.

```{r}
payments <- read_csv("data/State_of_Maryland_Payments_Data__FY2008_to_FY2024.csv", guess_max=373564)
```

### Task 4: Examine the data with glimpse

**Task** Run the following codeblock to glimpse the data. What data type is the "Vendor Name" field? What data type is the "Amount" field? What data type is the "Date" column? Answer below. 

**Answer** The "Vendor Name" and "Date" are characters or <chr>, while "Amount" is a number or <dbl>.

```{r}
glimpse(payments)
```

Things that should be characters -- like agency name, vendor name -- are characters (chr). Things that should be numbers (dbl) -- like amount and fiscal year -- are numbers. We've seen before that sometimes dates aren't defined as date datatypes by R - we can fix that using `lubridate`.

### Task 5: Detect wrong spatial data

The second smell we can find in code is **wrong spatial data**. Spatial data means data that refers to some geography; in this dataset the only geographical element is the vendor's zip code. Zip codes should be, at a minimum, five characters long (although composed of numbers, zip codes aren't used as numbers).

We can check to see if any of the zip codes are less than five characters by using [a function called `str_length`](https://stringr.tidyverse.org/reference/str_length.html) inside a filter.

**Task** Run the following codeblock to group by the vendor's zip code and show any that are less than five characters in length. How many zip codes do not have five characters? What do you think explains those records? 

**Answer** There are literally thousands of records here with zip codes that don't have five characters. That's so weird and seems very inaccurate! I assume most of these belong to Canadian or other foreign countries, or people just put their zip codes in incorrectly.

```{r}
payments |>
  filter(str_length(`Vendor Zip`) < 5) |> 
  group_by(`Vendor Zip`) |>
  summarise(
    count=n()
  ) |>
  arrange(desc(count))
```

### Task 6: Load Maryland grant and loan data

Let's now look at **gaps in data**. These often occur when you have a date or time element in your data, but there are other potential gaps, too. To illustrate those, we're going to introduce some Maryland state grant and loan data from 2009 forward. Let's load it and take a look:

**Task** Run the following codeblock to load Maryland state government grant and loan data

```{r}
md_grants_loans <- read_csv("data/State_of_Maryland_Grant_and_Loan_Data__FY2009_to_FY2022.csv")
```

Each row represents a recipient of state grant or loan, along with information about their location and the state agency that provided the money. When we talk about gaps, often they indicate the administrative rules. Here's an example: let's count the number of payments in each category (Grant or Loan) by year in this dataset.

### Task 7: Looking at categories

**Task** Run the following codeblock and describe below what each line is doing. Looking at the results, what jumps out at you as potentially problematic? 

**Answer** When looking at the results, a few things jump out at me as potentially problematic. For example, there are a lot of N/As in the category column. There are also no loans for some years, which is a bit weird? Does that mean we only have grant data for some years. Furthermore, some categories have things that are neither grants or loans, i.e. Fiscal Year 2013 is listed as "L" and Fiscal Year 2017 is listed as "Contract".

```{r}
md_grants_loans |> 
  group_by(`Fiscal Year`, Category) |> 
  summarize(count = n()) |> 
  arrange(`Fiscal Year`)
```

Any time you are going to focus on a column for analysis, you should check for unusual values. Are there any unusually large values or unusually small values? Are there any values that raise immediate questions about the data? Let's look at the smallest amounts in the grants and loan data.

### Task 8: Find outliers

**Task** Run the following code to arrange the grants & loan data so that the smallest amount is first. Describe what you see. 

**Answer** The first thing I see is a $60 grant in 2009 by Catherine & Mary Gemmill Easement to Department of Natural Resources/Rural Legacy Program. This feels unreasonable and inaccurate, but there are also an insane amount of outliers here. Though there are some small grants in 2009, most of the smallest donations are in the 2010s.

```{r}
md_grants_loans |> 
  arrange(Amount)
```

## Data Cleaning, Part II

### Task 1: Install janitor

**Task** Run the following codeblock to install the janitor package.

```{r}
install.packages('janitor')
```

### Task 2: Load janitor

**Task** Run the following code to load janitor.

```{r}
library(janitor)
```

Let's continue with our Maryland grants and loans data that we worked with in the previous chapter. There are a number of issues with this data set that might get in the way of asking questions and receiving accurate answers. They are:

-   The column names have spaces in them. This isn't a deal-breaker, as we used this dataframe previously. But it does require that you do some things differently when writing code, and ideally you don't want spaces in your column names.
-   Inconsistent capitalization across multiple columns. Sometimes the grantee is capitalized, and other times not. Portions of the grantor name are sometimes capitalized. This issue will ruin your ability to count and add things using those columns.
-   The zip field mixes five digit ZIP codes and nine digit ZIP codes, and some of the records include spaces. If we wanted to group and count the number of loans in a given ZIP code, this inconsistency would not let us do that correctly.
-   The category column is inconsistent and has some missing values.

Let's get cleaning. Our goal will be to build up one block of code that does all the necessary cleaning in order to answer this question: which zip code has gotten the most amount of money from the Maryland Tourism Board?

### Task 3: Use clean_names()

**Task** Run the following codeblock to use the `clean_names()` function from janitor to standardize column names. How does it change the headers? Answer below.

**Answer** This cleaned up the headers by removing the spaces and capitalization, which makes it look so much cleaner and so much easier for R to read. Where there were spaces, this added underscores. It did not change the data whatsoever--only effecting the headers of columns.

```{r}
# cleaning function
cleaned_md_grants_loans <- md_grants_loans |>
  clean_names()

# display the cleaned dataset
cleaned_md_grants_loans
```

### Task 4: Use rename()

**Task** Run the following codeblock to use the clean_names() function from janitor to standardize column names and then use rename() to change the "grantor" column to "source". With `rename()` the new name comes first!

```{r}
# cleaning function
cleaned_md_grants_loans <- md_grants_loans |>
  clean_names() |> 
  rename(source = grantor)

# display the cleaned dataset
cleaned_md_grants_loans
```

Right now the `source`, `grantee` and `description` columns have inconsistent capitalization. We can fix that using a mutate statement and a function that changes the case of text called `str_to_upper()`. We'll use the same columns, overwriting what's in there since all we're doing is changing case.

### Task 5: Using str_to_upper() to standardize case

**Task** Run the following codeblock to use str_to_upper() to make the source, grantee and description columns upper-cased. Describe what each line is doing.

**Answer** This made every single line uppercase, making everything significantly more consistent.

```{r}
# cleaning function
cleaned_md_grants_loans <- md_grants_loans |>
  clean_names() |> 
  rename(source = grantor) |> 
  mutate(source = str_to_upper(source), grantee = str_to_upper(grantee), description = str_to_upper(description))

# display the cleaned dataset
cleaned_md_grants_loans
```

### Task 6: Check for duplicate rows

**Task** Run the following codeblock to check for duplicate rows using get_dupes(). How many duplicates are possible? 

**Answer** This function found 50 records that appeared to be entire duplicates--meaning 25 duplicates exist. Though it might mean that these are entire duplicates, it could also mean that the same grantee got the same grant multiple times within a fiscal year.The data just describes when the data was generated, not when the grant was given.

```{r}
cleaned_md_grants_loans |>
  get_dupes()
```

### Task 7: Get rid of duplicate rows

**Task** Run the following codeblock to use distinct() to get rid of duplicate rows. How many rows does the new dataframe have? Answer below. 

**Answer** 17,740 rows

```{r}
# cleaning function
cleaned_md_grants_loans <- md_grants_loans |>
  clean_names() |> 
  rename(source = grantor) |> 
  mutate(source = str_to_upper(source), grantee = str_to_upper(grantee), description = str_to_upper(description)) |> 
  distinct()

# display the cleaned dataset
cleaned_md_grants_loans
```

### Task 8: Clean up ZIP code

The rest of the problems with this data set all have to do with inconsistent format of values in a few of the columns. To fix these problems, we're going to make use of mutate() in concert with "string functions" -- special functions that allow us to clean up columns stored as character strings. The tidyverse package `stringr` has lots of useful string functions that you can look up!

Let's start by cleaning up the zip field. Remember, some of the rows had a five-digit ZIP code, while others had a nine-digit ZIP code, separated by a hyphen or not.

We're going to write code that tells R to make a new column for our zips, keeping the first five digits on the left, and get rid of anything after that by using `mutate()` in concert with `str_sub()`, from the `stringr` package.

**Task** Run the following codeblock to use str_sub() to convert the ZIP codes that have nine digits to five digits, creating a new column. Look at the difference in the result - what changed? 

**Answer** We now have a zip5 column that's only 5 digits long. That str_sub  function gives us just a portion of that column. 

```{r}
# cleaning function
cleaned_md_grants_loans <- md_grants_loans |>
  clean_names() |> 
  rename(source = grantor) |> 
  mutate(source = str_to_upper(source), grantee = str_to_upper(grantee), description = str_to_upper(description)) |> 
  distinct() |>
  mutate(zip5 = str_sub(zip_code, start=1L, end=5L))


# display the cleaned dataset
cleaned_md_grants_loans
```

### Task 9: Clean up zip5 field more with case_when()

**Task** Run the following codeblock to use case_when() to change clear non-zip codes into NA values.

```{r}
# cleaning function
cleaned_md_grants_loans <- md_grants_loans |>
  clean_names() |> 
  rename(source = grantor) |> 
  mutate(source = str_to_upper(source), grantee = str_to_upper(grantee), description = str_to_upper(description)) |> 
  distinct() |>
  mutate(zip5 = str_sub(zip_code, start=1L, end=5L)) |>
  mutate(zip5 = case_when(
    zip5 == "Vario" ~ NA,
    zip5 == "UB7 O" ~ NA,
    zip5 == "UB7 " ~ NA,
    .default = zip5
  ))

# display the cleaned dataset
cleaned_md_grants_loans
```

### Task 10: Answer our question!

**Task** Write and run code to answer our original question: which zip code has gotten the most amount of money from the Maryland Tourism Board? Where is that zip code, and does that zip code make sense to you as the top recipient? Write a sentence describing the top result.

which zip code -> group_by(zip5)
most amount of money -> summarize()
from the maryland tourism board -> filter()

**Answer** The zip codes that have gotten the most amount of money from the Maryland Tourism Board are 21202 and 21601, which are Baltimore County and Tabolt County. Baltimore makes sense to me because it's such a big county, but Talbot doesn't since it's significantly smaller. I am a bit confused though because the amount coinciding with each of these zip codes is just 2, whereas the other counties say 1. I think I did something wrong with my summarize function, but I'm not quite sure how to fix it -- unless this means to say that each of these counties receieved 2 grants while the rest received less but this seems unlikely as well.

```{r}
# cleaning function
cleaned_md_grants_loans |>
  filter(source == 'COMMERCE/MARYLAND TOURISM BOARD') |> 
  group_by(zip5) |>
  summarise(
    total=sum(amount)
  ) |>
  
  arrange(desc(total))
```
